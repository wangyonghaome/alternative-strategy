{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from select_stock_pool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 20191101\n",
    "conn = pymysql.connect(**DB_INFO, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 get_accural_info 2019-12-13 15:10:54.918763\n",
      "Reading sql AShareIndustriesClassCITICS\n",
      "Reading sql AShareBalanceSheet\n",
      "Reading sql AShareIncome\n",
      "Reading sql AShareCashFlow\n",
      "\n",
      " 1 get_construct_info 2019-12-13 15:11:10.141776\n",
      "Reading sql AShareIndustriesClassCITICS\n",
      "Reading sql AShareBalanceSheet\n",
      "Reading sql AShareCashFlow\n",
      "\n",
      " 2 get_rd_account_info 2019-12-13 15:11:29.585777\n",
      "Reading sql WindCustomCode\n",
      "Reading sql AShareRDexpenditure\n",
      "Reading sql AShareIncome\n",
      "Reading sql AShareAuditOpinion\n",
      "\n",
      " 3 get_capital_risk_info 2019-12-13 15:12:13.929471\n",
      "Reading sql ASharePledgeproportion\n",
      "Reading sql AShareCapitalization\n",
      "Reading sql AEquFroPleInfoRepperend\n",
      "Reading sql AShareFloatHolder\n",
      "\n",
      " 4 get_manager_leave_info 2019-12-13 15:13:08.377816\n",
      "Reading sql AShareManagement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywang/proj_negative_alpha/select_stock_pool.py:385: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  manager_leave_ratio = np.sum(sr_manager_leave) / np.sum(df.s_info_manager_type == 1)\n",
      "/home/ywang/proj_negative_alpha/select_stock_pool.py:385: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  manager_leave_ratio = np.sum(sr_manager_leave) / np.sum(df.s_info_manager_type == 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5 get_inter_control_info 2019-12-13 15:13:19.964734\n",
      "Reading sql AShareDescription\n",
      "Reading sql AShareIssuingDatePredict\n",
      "Reading sql AShareIllegality\n",
      "Reading sql AShareRegInv\n",
      "Reading sql AShareProsecution\n",
      "Reading sql AShareProfitNotice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywang/proj_negative_alpha/select_stock_pool.py:490: RuntimeWarning: Mean of empty slice\n",
      "  sr_unaccuracy_notice = 1.0 * ((sr_notice_lowerbound - sr_profit)/sr_notice_lowerbound).groupby('sid').apply(lambda x: np.nanmean(x))#连续型变量\n",
      "/home/ywang/env/dev/lib/python3.6/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6 get_over_invest_info 2019-12-13 15:13:41.131076\n",
      "Reading sql AShareBalanceSheet\n",
      "Reading sql MergerParticipant\n",
      "Reading sql MergerEvent\n",
      "\n",
      " 7 get_related_trade_info 2019-12-13 15:14:06.454698\n",
      "Reading sql WindCustomCode\n",
      "Reading sql AShareBalanceSheet\n",
      "Reading sql AShareRalatedTrade\n",
      "Reading sql AShareRelatedclaimsdebts\n",
      "Reading sql MergerParticipant\n",
      "Reading sql MergerEvent\n",
      "\n",
      " 8 get_analyst_expect_info 2019-12-13 15:14:22.973300\n",
      "Reading sql AShareStockRatingConsus\n",
      "Reading sql AShareConsensusRollingData\n",
      "\n",
      " 9 get_holder_trade_info 2019-12-13 15:14:50.047359\n",
      "Reading sql AShareCapitalization\n",
      "Reading sql AShareMjrHolderTrade\n",
      "\n",
      " 10 get_risk_event_info 2019-12-13 15:14:53.914138\n",
      "Reading sql MergerParticipant\n",
      "Reading sql MergerEvent\n",
      "Reading sql AShareCompRestricted\n",
      "Reading sql AShareMajorEvent\n",
      "\n",
      " 11 get_finance_report_info 2019-12-13 15:16:00.818191\n",
      "Reading sql WindCustomCode\n",
      "Reading sql AShareIncome\n",
      "Reading sql AShareProfitNotice\n",
      "Reading sql AShareAuditOpinion\n",
      "Reading sql AShareGovernmentgrants\n",
      "\n",
      " 2019-12-13 15:16:10.725388\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "mod = importlib.import_module(f'select_stock_pool')\n",
    "func_names = ['get_accural_info', 'get_construct_info', 'get_rd_account_info', 'get_capital_risk_info', 'get_manager_leave_info', \n",
    "              'get_inter_control_info', 'get_over_invest_info', 'get_related_trade_info', 'get_analyst_expect_info', 'get_holder_trade_info',\n",
    "              'get_risk_event_info', 'get_finance_report_info']\n",
    "\n",
    "res = []\n",
    "\n",
    "for i, func_name in enumerate(func_names):\n",
    "    func = getattr(mod, func_name)\n",
    "    print('\\n', i, func_name, pd.datetime.now())\n",
    "    res.append(func(date, conn))\n",
    "print('\\n', pd.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, ele in enumerate(res2):\n",
    "#     assert np.all(ele.index[:-1] < ele.index[1:])\n",
    "#     # print(i+1, ele.name, ele.index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_tools.api import query_table, trade_days, is_trade_date, get_trade_dates\n",
    "def get_stk_descr(conn):\n",
    "    table_name = 'wind.ASHAREDESCRIPTION'\n",
    "    cols_map = {'S_INFO_WINDCODE': 'sid', 'S_INFO_NAME': 'name',\n",
    "                'S_INFO_LISTDATE': 'list_date', 'S_INFO_DELISTDATE': 'delist_date'}\n",
    "    sql = f\"SELECT %s FROM %s\" % (', '.join(list(cols_map.keys())), table_name)\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "    df.rename(cols_map, axis=1, inplace=True)\n",
    "    df = df.sort_values(by=['sid'], ascending=True)\n",
    "    df = df[(df.sid.apply(lambda x: x is not None)) \n",
    "            & (df.sid.apply(lambda x: x[::8] in ['0Z', '3Z', '6H']))]\n",
    "    df = df.replace([None], '99999999')\n",
    "    df['list_date'] = df['list_date'].values.astype('i4')\n",
    "    df['delist_date'] = df['delist_date'].values.astype('i4')\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_db_info(date, conn):\n",
    "    start_date = get_prev_n_trade_date(date, 59)\n",
    "    df_data = query_table('DailyBar', start_date, date, ['close', 'amount', 'IPODays', 'ST'])\n",
    "    df_data.sort_values(['DataDate', 'sid'], inplace=True)\n",
    "    \n",
    "    unique_dates = np.sort(np.unique(df_data.DataDate.values))\n",
    "    unique_sids = np.sort(np.unique(df_data.sid.values))\n",
    "    dates_pos = np.searchsorted(unique_dates, df_data.DataDate.values)\n",
    "    sids_pos = np.searchsorted(unique_sids, df_data.sid.values)\n",
    "    m, n = len(unique_dates), len(unique_sids)\n",
    "    assert m == 60\n",
    "    \n",
    "    d = dict()\n",
    "    for fl in ['close', 'amount', 'IPODays', 'ST']:\n",
    "        d[fl] = np.full([m, n], np.nan)\n",
    "        d[fl][dates_pos, sids_pos] = df_data[fl].values\n",
    "\n",
    "    cond_list = 1.0 * (d['IPODays'][-1] < 120) # 剔除的为1\n",
    "    cond_st = 1.0 * (d['ST'][-1] == 1.0)\n",
    "    cond_amount = np.full([n,], 0.0)\n",
    "    for j in range(n):\n",
    "        arr = d['amount'][:,j]\n",
    "        arr2 = arr[~(np.isnan(arr)) & (arr>0)]\n",
    "        if len(arr2) < 20:\n",
    "            continue\n",
    "        arr2 = arr2[-20:]\n",
    "        pos = np.argmax(arr2)\n",
    "        mean_amount = (np.sum(arr2) - arr2[pos]) / 19\n",
    "        cond_amount[j] = 1.0 * (mean_amount < 2.e7)\n",
    "    \n",
    "    pos = np.searchsorted(dates_pos, dates_pos[-1])\n",
    "    df_res = pd.DataFrame([], index=unique_sids[sids_pos[pos:]])\n",
    "    df_res['list_days'] = cond_list[sids_pos[pos:]]\n",
    "    df_res['st'] = cond_st[sids_pos[pos:]]\n",
    "    df_res['amount'] = cond_amount[sids_pos[pos:]]\n",
    "    df_res.index.name = 'sid'\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywang/env/dev/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "res2 = list(chain(*res))\n",
    "\n",
    "df_db = get_db_info(date, conn)\n",
    "for ele in res2:\n",
    "    ele2 = ele.reindex(df_db.index)\n",
    "    df_db[ele2.name] = ele2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accural_profit 75\n",
      "accural_abnormal 74\n",
      "manipulate 71\n",
      "construct_growth 65\n",
      "rd_ratio 63\n",
      "change_audit 543\n",
      "pledge_ratio 72\n",
      "fro_ple_ratio 54\n",
      "top10_trust_ratio 74\n",
      "top10_trust_num 76\n",
      "cfo_leave 150\n",
      "manager_leave 169\n",
      "illegality 29\n",
      "reginv 67\n",
      "prosecution 28\n",
      "unaccuracy_notice 55\n",
      "goodwill_ratio 44\n",
      "merger_times 57\n",
      "related_sellbuy_ratio 31\n",
      "related_debts_ratio 14\n",
      "related_merger_ratio 6\n",
      "related_trade_num 47\n",
      "rating_delta 24\n",
      "est_price_delta 21\n",
      "eps_delta 38\n",
      "holder_sell 11\n",
      "manager_sell 8\n",
      "merger_failure 27\n",
      "restricted_ratio 2\n",
      "bond_default 27\n",
      "enquiry_letter 32\n",
      "actual_deficit 450\n",
      "notice_deficit 132\n",
      "notice_collapse 101\n",
      "audit_opinion 210\n",
      "grants_ratio 53\n"
     ]
    }
   ],
   "source": [
    "stock_pool=set()\n",
    "for item in df_db.columns[3:]:\n",
    "    if item=='issuing_delay':\n",
    "        continue\n",
    "    risk_item = df_db[item].dropna()\n",
    "    if len(risk_item)==0:\n",
    "        continue\n",
    "    bound_value = np.percentile(risk_item,98)\n",
    "    risk_stock=risk_item[risk_item>=bound_value].index\n",
    "    print(item,len(risk_stock))\n",
    "    stock_pool=stock_pool|set(risk_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
