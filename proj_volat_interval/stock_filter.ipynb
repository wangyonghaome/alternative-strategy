{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from data_tools.api import *\r\n",
    "from utilscht.Data import *\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.backends.backend_pdf import PdfPages\r\n",
    "from volat_calcu import *\r\n",
    "import pymysql\r\n",
    "from joblib import Parallel,delayed\r\n",
    "%config InlineBackend.figure_format ='retina'\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "from reader import *\r\n",
    "\r\n",
    "\r\n",
    "DB_INFO = dict(host='192.168.1.234',\r\n",
    "               user='winduser',\r\n",
    "               password='1qaz@WSX',\r\n",
    "               db='wind')\r\n",
    "\r\n",
    "conn = pymysql.connect(**DB_INFO, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def apply_parallel(df_grouped, func, n_jobs=16, backend='loky', as_index=True, ratio=0.1):\r\n",
    "    \"\"\"\r\n",
    "    This is for parallel between grouped generated by pd.DataFrame.groupby\r\n",
    "    :param df_grouped:\r\n",
    "    :param func:\r\n",
    "    :param n_jobs:\r\n",
    "    :param backend:\r\n",
    "    :param kwargs:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    names = []\r\n",
    "    groups = []\r\n",
    "    for name, group in df_grouped:\r\n",
    "        names.append(name)\r\n",
    "        groups.append(group)\r\n",
    "\r\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=5, backend=backend, batch_size='auto') \\\r\n",
    "        (delayed(func)(group) for group in groups)\r\n",
    "\r\n",
    "    return pd.concat(results, keys=names if as_index else None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from data_tools.api import trade_days\r\n",
    "\r\n",
    "trade_dates_all = trade_days.copy()\r\n",
    "def get_prev_n_trade_date(trade_date, n):\r\n",
    "    trade_date=str(trade_date)[0:10].replace('-','')\r\n",
    "    pos = np.searchsorted(trade_dates_all, trade_date)\r\n",
    "    try:\r\n",
    "        assert pos >= n\r\n",
    "        return str(trade_dates_all[pos - n])\r\n",
    "    except AssertionError:\r\n",
    "        return \"20200101\"\r\n",
    "\r\n",
    "def get_next_n_trade_date(trade_date, n=1):\r\n",
    "    trade_date=str(trade_date)[0:10].replace('-','')\r\n",
    "    pos = np.searchsorted(trade_dates_all, trade_date, side='right')\r\n",
    "    try:\r\n",
    "        assert pos + n - 1 < len(trade_dates_all)\r\n",
    "        return str(trade_dates_all[pos + n - 1])\r\n",
    "    except AssertionError:\r\n",
    "        return \"20201231\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 只取20交易日内触发止损止盈的，且20交易日内不重复买入同一支股票\r\n",
    "def get_date_stop_pl(df,ratio = 0.1):\r\n",
    "    sid = df[\"sid\"].iloc[0]\r\n",
    "    date = df[\"date\"].iloc[0]\r\n",
    "    hq_data = get_stk_bar(sid,start=date,end=get_next_n_trade_date(date,21),fields=[\"adj_close\",'adj_high',\"adj_low\"])\r\n",
    "    thr_up= hq_data[\"adj_close\"].values[0]*(1+ratio)\r\n",
    "    thr_down= hq_data[\"adj_close\"].values[0]*(1-ratio)\r\n",
    "    \r\n",
    "    df=pd.DataFrame(index=[0],columns=[\"date_{}p_ud\".format(int(ratio*100)),\"up_down\"])\r\n",
    "    for dt in hq_data.index[1:21]:\r\n",
    "        if hq_data.loc[dt,\"adj_high\"] > thr_up:\r\n",
    "            df.iloc[0]=(str(dt)[0:10], 1)\r\n",
    "            return df\r\n",
    "        if hq_data.loc[dt,\"adj_low\"] < thr_down:\r\n",
    "            df.iloc[0]=(str(dt)[0:10],-1)\r\n",
    "            return df\r\n",
    "    \r\n",
    "    change_rate = hq_data.loc[dt,\"adj_close\"]/hq_data[\"adj_close\"].values[0]-1\r\n",
    "    df.iloc[0]=(str(dt)[0:10],change_rate)\r\n",
    "    return df\r\n",
    "\r\n",
    "def date_filter(df):\r\n",
    "    use_dates=[]\r\n",
    "    date_list = df[\"date\"].values\r\n",
    "    while(1):\r\n",
    "        if len(date_list)==0:\r\n",
    "            break\r\n",
    "        else:\r\n",
    "            date =  min(date_list)\r\n",
    "            use_dates.append(date)\r\n",
    "            dates_rm = get_trade_dates(date,min(get_next_n_trade_date(date,19),\"20191231\"))\r\n",
    "            date_list=list(set(date_list)-set(dates_rm))\r\n",
    "    return df[df[\"date\"].isin(use_dates)]\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 统计白马股票日内穿网格的次数满足要求的日期"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "trade_dates=get_trade_dates('20180101',\"20200331\")\r\n",
    "trade_dates=[str(i) for i in trade_dates]\r\n",
    "\r\n",
    "df_cross_grid_count=pd.DataFrame()\r\n",
    "for date in trade_dates:\r\n",
    "    stock_pool=pd.read_csv(r\"/share/xfzhang/to_colleague/to_yzhao/task2/{}/{}/task2_{}.csv\".format(date[0:4],date[4:6],date[0:8]))[\"sid\"]\r\n",
    "    cross_grid=pd.read_excel(r\"/home/ywang/proj_cross_grid/result/cross_count_b240/crosscount_summary_{}.xlsx\".format(date))\r\n",
    "    cross_grid=cross_grid.set_index(\"sid\").loc[stock_pool].reset_index()[['sid','5d_count','10d_count']]\r\n",
    "    cross_grid[\"date\"]=date\r\n",
    "    \r\n",
    "    df_cross_grid_count=pd.concat([df_cross_grid_count,cross_grid])\r\n",
    "\r\n",
    "df_cross_grid_count=df_cross_grid_count[(df_cross_grid_count[\"5d_count\"]>=20) & (df_cross_grid_count[\"10d_count\"]>=40)]\r\n",
    "df_cross_grid_count=df_cross_grid_count.set_index(\"date\").reset_index().sort_values(by=[\"date\",\"sid\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ywang/env/dev/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def get_change_to_60d_high(sid,date):\r\n",
    "    df_stk_price = get_stk_bar(sid,start=get_prev_n_trade_date(date,60),\\\r\n",
    "                               end = get_previous_trade_date(date),fields =[\"adj_high\",\"adj_close\",\"adj_factor\"])\r\n",
    "    price_60d_high =    np.nanmax(df_stk_price[\"adj_high\"])\r\n",
    "    adj_factor_yd = df_stk_price[\"adj_factor\"].iloc[-1]\r\n",
    "    price_yd_close = df_stk_price[\"adj_close\"].iloc[-1]/ adj_factor_yd    \r\n",
    "    \r\n",
    "    with BarReader('/home/ywang/proj_cross_grid/reader/bar.yaml') as client:\r\n",
    "        bars = client.stock_bars(\"000001\")\r\n",
    "        hq_df = pd.DataFrame(bars)\r\n",
    "        pre_close = hq_df[\"preclose\"].iloc[0]\r\n",
    "        adj_factor_td = adj_factor_yd*price_yd_close/pre_close\r\n",
    "        adj_high_td =  np.nanmax(hq_df[\"high\"])*adj_factor_td\r\n",
    "        adj_close_td = hq_df[\"close\"].dropna().iloc[-1]*adj_factor_td\r\n",
    "\r\n",
    "    change_to_60d_high = (max(price_60d_high,adj_high_td) - adj_close_td )/ max(price_60d_high,adj_high_td)\r\n",
    "    \r\n",
    "    return change_to_60d_high\r\n",
    "\r\n",
    "cross_grid_summary_to_renew[\"change_to_60d_high\"] = cross_grid_summary_to_renew[[\"sid\",\"date\"]]\\\r\n",
    "                                            .apply(lambda x:get_change_to_60d_high(x[0],x[1]),axis = 1)\r\n",
    "cross_grid_summary_to_renew = cross_grid_summary_to_renew.sort_values(\"change_to_60d_high\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run stock_pool_renew_v240.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df= pd.read_excel(r\"result/穿网格五天大于20十天大于40_白马_全部.xlsx\",dtype={\"date\":str})\r\n",
    "df= df.sort_values([\"date\",\"change_to_60d_high\"])\r\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "df.to_excel(r\"result/穿网格五天大于20十天大于40_白马_全部.xlsx\",index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 记录第一次涨跌10%的日期（只记20d之内涨跌10%的情况，20天内连续触发只记第一次）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#日期筛选 + 上下跌破标注\r\n",
    "group = df_cross_grid_count.groupby([\"sid\",\"date\"])\r\n",
    "df_date_stop_pl=apply_parallel(group,get_date_stop_pl).reset_index().\\\r\n",
    "                rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "df_cross_grid_count_1=pd.merge(df_cross_grid_count,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "df_cross_grid_count_1.to_excel(r\"result/穿网格五天大于20十天大于40_白马_全部.xlsx\",index=False)\r\n",
    "\r\n",
    "#df_cross_grid_count=df_cross_grid_count.drop(['date_10p_ud','up_down'],axis=1)\r\n",
    "df_cross_grid_count_2 = df_cross_grid_count.groupby(\"sid\").apply(date_filter).reset_index(drop=True)\r\n",
    "group = df_cross_grid_count_2.groupby([\"sid\",\"date\"])\r\n",
    "df_date_stop_pl=apply_parallel(group,get_date_stop_pl).reset_index().\\\r\n",
    "                rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "\r\n",
    "df_cross_grid_count_2=pd.merge(df_cross_grid_count_2,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "df_cross_grid_count_2.to_excel(r\"result/穿网格五天大于20十天大于40_白马_20天内不重复触发.xlsx\",index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 改变止损止盈点，观察胜率变化"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_win_ratio = pd.DataFrame(index=np.linspace(0.10,0.30,21),columns=[\"win_ratio\",\"count\"])\r\n",
    "\r\n",
    "for ratio in np.linspace(0.10,0.30,21):\r\n",
    "    #df_cross_grid_count=df_cross_grid_count.drop(['date_10p_ud','up_down'],axis=1)\r\n",
    "    df_cross_grid_count_2 = df_cross_grid_count.groupby(\"sid\").apply(date_filter).reset_index(drop=True)\r\n",
    "    group = df_cross_grid_count_2.groupby([\"sid\",\"date\"])\r\n",
    "    df_date_stop_pl=apply_parallel(group,get_date_stop_pl,ratio=ratio).reset_index().\\\r\n",
    "                    rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "    df_cross_grid_count_2=pd.merge(df_cross_grid_count_2,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "    df_win_ratio.loc[ratio,\"win_ratio\"]=len(df_cross_grid_count_2[df_cross_grid_count_2[\"up_down\"]==1])\\\r\n",
    "                                /len(df_cross_grid_count_2[df_cross_grid_count_2[\"up_down\"]==-1])\r\n",
    "    df_win_ratio.loc[ratio,\"count\"] = len(df_cross_grid_count_2[pd.notnull(df_cross_grid_count_2[\"up_down\"])])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_win_ratio[\"win_ratio\"]=df_win_ratio[\"win_ratio\"]/(1+df_win_ratio[\"win_ratio\"])\r\n",
    "df_win_ratio[\"total_profit\"]= df_win_ratio[\"count\"] * (2*df_win_ratio[\"win_ratio\"]-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 统计底仓股票日内穿网格的次数满足要求的日期"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_stk_data(sid, date):\r\n",
    "    \r\n",
    "    try:\r\n",
    "        raw_bar_dtype = [\r\n",
    "            ('sid', '<U16'),\r\n",
    "            ('DataDate', 'i4'),\r\n",
    "            ('ticktime', 'i4'),\r\n",
    "            ('pre_close', 'f8'),\r\n",
    "            ('open', 'f8'),\r\n",
    "            ('high', 'f8'),\r\n",
    "            ('low', 'f8'),\r\n",
    "            ('close', 'f8'),\r\n",
    "            ('volume', 'f8'),\r\n",
    "            ('amount', 'f8'),\r\n",
    "            ('bid_amount', 'f8'),\r\n",
    "            ('ask_amount', 'f8'),\r\n",
    "            ('vwap', 'f8'),\r\n",
    "            ('twap', 'f8'),\r\n",
    "            ('ret', 'f8')\r\n",
    "        ]\r\n",
    "\r\n",
    "\r\n",
    "        bar=np.memmap(r\"/share/intern_share/dat/stk_bar/1min/2019/{}/{}.dat\".format(date,sid),dtype=raw_bar_dtype,mode=\"r\")\r\n",
    "        stock_data=pd.DataFrame(bar)[[\"sid\",\"DataDate\",\"ticktime\",\"open\", \"high\", \"low\", \"close\",\"pre_close\"]]\r\n",
    "        stock_data[\"ticktime\"]=stock_data.index\r\n",
    "        return stock_data\r\n",
    "    except:\r\n",
    "        try:\r\n",
    "            stock_data = get_stk_bar(sid, freq=\"1m\", start=date, end=date, fields=[\"open\", \"high\", \"low\", \"close\"])\r\n",
    "            stock_data = stock_data.reset_index().rename(columns={\"index\": \"datetime\"})\r\n",
    "            stock_data[\"ticktime\"] = stock_data[\"datetime\"].index\r\n",
    "            stock_data[\"DataDate\"] = stock_data[\"datetime\"].apply(lambda x:str(x.date()))\r\n",
    "            del stock_data[\"datetime\"]\r\n",
    "            stock_data[\"pre_close\"] = get_stk_bar(sid, freq=\"1d\", start=date, end=date, fields=[\"pre_close\"]).values[0][0]\r\n",
    "            stock_data[\"sid\"] = sid\r\n",
    "            return stock_data\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "\r\n",
    "\r\n",
    "def get_daily_data(date):\r\n",
    "    df=query_table(\"DailyBar\",start_date=date,end_date=date,fields=[\"tradable\"])\r\n",
    "    stk_ls=list(df[\"sid\"][df[\"tradable\"]==1])\r\n",
    "\r\n",
    "    results = Parallel(n_jobs=16, verbose=5, backend=\"loky\", batch_size='auto') \\\r\n",
    "        (delayed(get_stk_data)(sid, date) for sid in stk_ls)\r\n",
    "    data = pd.concat(results)\r\n",
    "\r\n",
    "    return data.sort_values([\"sid\", \"ticktime\"])\r\n",
    "\r\n",
    "def get_intraday_decre(df):\r\n",
    "    price_low = np.min(df[\"low\"].iloc[0:220])\r\n",
    "    pre_close = df[\"pre_close\"].iloc[0]\r\n",
    "    return price_low/pre_close-1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## V1--2:40分界点"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trade_dates=get_trade_dates('20170301',\"20191224\")\r\n",
    "trade_dates=[str(i) for i in trade_dates]\r\n",
    "\r\n",
    "df_cross_grid_count_240=pd.DataFrame()\r\n",
    "for date in trade_dates:\r\n",
    "    stock_pool=pd.read_csv(r\"/share/xfzhang/to_colleague/to_yzhao/task2_v2/{}/{}/task2_v2_{}.csv\".format(date[0:4],date[4:6],date[0:8]))[\"sid\"]\r\n",
    "    \r\n",
    "    df_daily_price=get_daily_data(date).set_index(\"sid\").loc[stock_pool].reset_index()\r\n",
    "    df_intraday_decre = df_daily_price.groupby(\"sid\").apply(get_intraday_decre).to_frame(\"intraday_decre\")\r\n",
    "    stock_pool = df_intraday_decre[df_intraday_decre[\"intraday_decre\"] < -0.03].reset_index()\r\n",
    "    \r\n",
    "    cross_grid=pd.read_excel(r'/home/ywang/proj_cross_grid/result/cross_count_b240/crosscount_summary_{}.xlsx'.format(date))\r\n",
    "    cross_grid=cross_grid.merge(stock_pool,on='sid')[['sid','5d_count','10d_count',\"intraday_decre\"]]\r\n",
    "    cross_grid[\"date\"]=date\r\n",
    "    \r\n",
    "    df_cross_grid_count_240=pd.concat([df_cross_grid_count_240,cross_grid])\r\n",
    "\r\n",
    "df_cross_grid_count_240=df_cross_grid_count_240[(df_cross_grid_count_240[\"5d_count\"]>=50) & (df_cross_grid_count_240[\"10d_count\"]>=100)]\r\n",
    "df_cross_grid_count_240=df_cross_grid_count_240.set_index(\"date\").reset_index().sort_values(by=[\"sid\",\"date\"])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## V2--3:00分界点"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "trade_dates=get_trade_dates('20170222',\"20191229\")\r\n",
    "trade_dates=[str(i) for i in trade_dates]\r\n",
    "\r\n",
    "df_cross_grid_count_300=pd.DataFrame()\r\n",
    "for date in trade_dates:\r\n",
    "    stock_pool=pd.read_csv(r\"/share/xfzhang/to_colleague/to_yzhao/task2_v2/{}/{}/task2_v2_{}.csv\".format(date[0:4],date[4:6],date[0:8]))[\"sid\"]\r\n",
    "    \r\n",
    "    df_daily_price=query_table(\"DailyBar\",date,date,fields=[\"pre_close\",\"low\"])\r\n",
    "    df_daily_price=df_daily_price.set_index(\"sid\").loc[stock_pool.values].reset_index()\r\n",
    "    df_daily_price[\"intraday_decre\"] = df_daily_price[\"low\"] / df_daily_price[\"pre_close\"]-1\r\n",
    "    stock_pool = df_daily_price[[\"sid\",\"intraday_decre\"]][df_daily_price[\"intraday_decre\"]<-0.03]\r\n",
    "    \r\n",
    "    cross_grid=pd.read_excel(r'/share/intern_share/stk_bundle_v2/crosscount_summary_{}.xlsx'.format(date))\r\n",
    "    cross_grid=cross_grid.merge(stock_pool,on='sid')[['sid','5d_count','10d_count',\"intraday_decre\"]]\r\n",
    "    cross_grid[\"date\"]=date\r\n",
    "    \r\n",
    "    df_cross_grid_count_300=pd.concat([df_cross_grid_count_300,cross_grid])\r\n",
    "\r\n",
    "df_cross_grid_count_300=df_cross_grid_count_300[(df_cross_grid_count_300[\"5d_count\"]>=50) & (df_cross_grid_count_300[\"10d_count\"]>=100)]\r\n",
    "df_cross_grid_count_300=df_cross_grid_count_300.set_index(\"date\").reset_index().sort_values(by=[\"sid\",\"date\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ywang/env/dev/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 当日或者前一日涨跌停股票"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "df_cross_count = pd.read_excel(r\"result/穿网格五天大于50十天大于100盘中跌超3%_底仓_nodatefilter_17_19_止盈止损15%.xlsx\")\r\n",
    "df_if_limit= query_table(\"DailyBar\",start_date=\"20170101\",end_date=\"20191224\",fields=[\"if_limit\"])\r\n",
    "df_if_limit_today = df_if_limit.rename(columns={\"DataDate\":\"date\",\"if_limit\":\"if_limit_today\"})\r\n",
    "df_cross_count = df_cross_count.merge(df_if_limit_today,on=[\"sid\",\"date\"])\r\n",
    "\"\"\"df_if_limit = df_if_limit.rename(columns={\"DataDate\":\"date_{}p_ud\".format(percent)})\r\n",
    "df_cross_count = df_cross_count.merge(df_if_limit,on=[\"sid\",\"date_{}p_ud\".format(percent)])\r\n",
    "df_cross_count = df_cross_count[df_cross_count[\"if_limit\"]==0.0]\"\"\"\r\n",
    "def get_next_date(df):\r\n",
    "    df=df.rename(columns={\"DataDate\":\"date\"})\r\n",
    "    date=int(get_next_trade_date(df[\"date\"].iloc[0]))\r\n",
    "    df[\"date\"] = date\r\n",
    "    return df.rename(columns={\"if_limit\":\"if_limit_yesterday\"})\r\n",
    "df_if_limit_yesterday = df_if_limit.groupby(\"DataDate\").apply(get_next_date)\r\n",
    "df_cross_count = df_cross_count.merge(df_if_limit_yesterday,on=[\"sid\",\"date\"])\r\n",
    "\r\n",
    "df_cross_count_drop = df_cross_count[(df_cross_count[\"if_limit_today\"]!=0.0) | (df_cross_count[\"if_limit_yesterday\"]!=0.0)]\r\n",
    "df_cross_count_drop.to_excel(r\"result/穿网格五天大于50十天大于100盘中跌超3%_底仓_止盈止损15%_当日或前一日涨跌停股票.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 记录第一次涨跌10%的日期（只记20d之内涨跌10%的情况，20天内连续触发只记第一次）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 日期筛选 + 上下跌破标注\r\n",
    "ratio=0.10\r\n",
    "group = df_cross_grid_count_300.groupby([\"sid\",\"date\"])\r\n",
    "df_date_stop_pl=apply_parallel(group,get_date_stop_pl,ratio=ratio).reset_index().\\\r\n",
    "                rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "df_cross_grid_count_1=pd.merge(df_cross_grid_count_300,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "df_cross_grid_count_1.to_excel(r\"result/穿网格五天大于50十天大于100盘中跌超3%_底仓_全部.xlsx\",index=False)\r\n",
    "\r\n",
    "#df_cross_grid_count_300=df_cross_grid_count_300.drop(['date_10p_ud','up_down'],axis=1)\r\n",
    "df_cross_grid_count_2 = df_cross_grid_count_300.groupby(\"sid\").apply(date_filter).reset_index(drop=True)\r\n",
    "group = df_cross_grid_count_2.groupby([\"sid\",\"date\"])\r\n",
    "df_date_stop_pl=apply_parallel(group,get_date_stop_pl,ratio=ratio).reset_index().\\\r\n",
    "                rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "\r\n",
    "df_cross_grid_count_2=pd.merge(df_cross_grid_count_2,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "df_cross_grid_count_2.to_excel(r\"result/穿网格五天大于50十天大于100盘中跌超3%_底仓_20天内不重复触发.xlsx\",index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%run stock_pool_renew.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 改变止损止盈点，观察胜率变化"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_win_ratio = pd.DataFrame(index=np.linspace(0.10,0.20,3),columns=[\"win_ratio\",\"count\"])\r\n",
    "\r\n",
    "for ratio in np.linspace(0.10,0.20,3):\r\n",
    "    #df_cross_grid_count=df_cross_grid_count.drop(['date_10p_ud','up_down'],axis=1)\r\n",
    "    #df_cross_grid_count_2 = df_cross_grid_count_240.groupby(\"sid\").apply(date_filter).reset_index(drop=True)\r\n",
    "    df_cross_grid_count_2 = df_cross_grid_count_300.copy()\r\n",
    "    group = df_cross_grid_count_2.groupby([\"sid\",\"date\"])\r\n",
    "    df_date_stop_pl=apply_parallel(group,get_date_stop_pl,ratio=ratio).reset_index().\\\r\n",
    "                    rename(columns={'level_0':'sid',\"level_1\":\"date\"}).drop(['level_2'],axis=1)\r\n",
    "    df_cross_grid_count_2=pd.merge(df_cross_grid_count_2,df_date_stop_pl,on=[\"sid\",\"date\"])\r\n",
    "    df_win_ratio.loc[ratio,\"win_ratio\"]=len(df_cross_grid_count_2[df_cross_grid_count_2[\"up_down\"]==1])\\\r\n",
    "                                /len(df_cross_grid_count_2[df_cross_grid_count_2[\"up_down\"]==-1])\r\n",
    "    df_win_ratio.loc[ratio,\"count\"] = len(df_cross_grid_count_2[pd.notnull(df_cross_grid_count_2[\"up_down\"])])\r\n",
    "    \r\n",
    "    df_cross_grid_count_2.to_excel(r\"result/穿网格五天大于50十天大于100盘中跌超3%_底仓_nodatefilter_17_19_止盈止损{}%.xlsx\".format(int(ratio*100)),index=False)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_win_ratio[\"win_ratio\"]=df_win_ratio[\"win_ratio\"]/(1+df_win_ratio[\"win_ratio\"])\r\n",
    "df_win_ratio[\"total_profit\"]= df_win_ratio[\"count\"] * (2*df_win_ratio[\"win_ratio\"]-1)\r\n",
    "df_win_ratio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 将白马股单独列出一个文件"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trade_dates=get_trade_dates('20190102',\"20191230\")\r\n",
    "\r\n",
    "for date in trade_dates:\r\n",
    "    stock_pool=pd.read_csv(r\"/share/xfzhang/to_colleague/to_yzhao/task2/{}/{}/task2_{}.csv\".format(date[0:4],date[4:6],date[0:8]))[\"sid\"]\r\n",
    "    cross_grid=pd.read_excel(r'/share/intern_share/stk_bundle_v2/crosscount_summary_{}.xlsx'.format(date))\r\n",
    "    cross_grid = cross_grid.set_index(\"sid\").loc[stock_pool]\r\n",
    "    \r\n",
    "    cross_grid.to_excel(r'/share/intern_share/stk_bundle_baima/crosscount_summary_{}.xlsx'.format(date))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 白马池回测，5d、10d同时高于买入，同时低于卖出"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from data_tools.api import trade_days\r\n",
    "trade_dates_all = trade_days.copy()\r\n",
    "def get_prev_n_trade_date(trade_date, n):\r\n",
    "    pos = np.searchsorted(trade_dates_all, trade_date)\r\n",
    "    assert pos >= n\r\n",
    "    return int(trade_dates_all[pos - n])\r\n",
    "\r\n",
    "def get_next_n_trade_date(trade_date, n=1):\r\n",
    "    pos = np.searchsorted(trade_dates_all, trade_date, side='right')\r\n",
    "    assert pos + n - 1 < len(trade_dates_all)\r\n",
    "    return int(trade_dates_all[pos + n - 1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trade_dates=get_trade_dates('20170222',\"20191230\")\r\n",
    "trade_dates=[str(i) for i in trade_dates]\r\n",
    "\r\n",
    "df_cross_grid_count=pd.DataFrame()\r\n",
    "for date in trade_dates:\r\n",
    "    stock_pool=pd.read_csv(r\"/share/xfzhang/to_colleague/to_yzhao/task2/{}/{}/task2_{}.csv\".format(date[0:4],date[4:6],date[0:8]))[\"sid\"]\r\n",
    "    cross_grid=pd.read_excel(r'/share/intern_share/stk_bundle_v2/crosscount_summary_{}.xlsx'.format(date))\r\n",
    "    cross_grid=cross_grid.set_index(\"sid\").loc[stock_pool].reset_index()[['sid','5d_count','10d_count']]\r\n",
    "    cross_grid[\"date\"]=date\r\n",
    "    \r\n",
    "    df_cross_grid_count=pd.concat([df_cross_grid_count,cross_grid])\r\n",
    "\r\n",
    "df_stk_pool_buy=df_cross_grid_count[(df_cross_grid_count[\"5d_count\"]>=20) & (df_cross_grid_count[\"10d_count\"]>=40)]\r\n",
    "df_stk_pool_buy=df_stk_pool_buy.set_index(\"date\").reset_index().sort_values(by=[\"sid\",\"date\"])\r\n",
    "\r\n",
    "df_stk_pool_sell=df_cross_grid_count[(df_cross_grid_count[\"5d_count\"]<20) & (df_cross_grid_count[\"10d_count\"]<40)]\r\n",
    "df_stk_pool_sell=df_stk_pool_sell.set_index(\"date\").reset_index().sort_values(by=[\"sid\",\"date\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stk_ls_holding = []\r\n",
    "port_ret_daily = pd.Series(index=pd.to_datetime(trade_dates[1:]))\r\n",
    "port_stk_num = pd.Series(index=pd.to_datetime(trade_dates[1:]))\r\n",
    "\r\n",
    "def get_daily_ret(stk_ls_holding,date,trade_calendar):\r\n",
    "    next_date= get_next_trade_date(date)\r\n",
    "    \r\n",
    "    today_price=query_table(\"DailyBar\",start_date=date,end_date=date,fields=[\"tradable\",\"adj_close\"])\r\n",
    "    today_price=today_price[today_price[\"tradable\"]==1]\r\n",
    "    \r\n",
    "    next_date_price=query_table(\"DailyBar\",start_date=next_date,end_date=next_date,fields=[\"tradable\",\"adj_close\"])\r\n",
    "    #next_date_price=next_date_price[next_date_price[\"tradable\"]==1]\r\n",
    "    \r\n",
    "    df_p_10d_price = query_table(\"DailyBar\",start_date=get_prev_n_trade_date(date,10),end_date=get_prev_n_trade_date(date,10),fields=[\"tradable\",\"adj_close\"])\r\n",
    "    #df_p_10d_price = df_p_10d_price[df_p_10d_price[\"tradable\"]==1]\r\n",
    "    \r\n",
    "    merged_price = pd.merge(df_p_10d_price,today_price,on= \"sid\" )\r\n",
    "    stk_incre = merged_price[merged_price[\"adj_close_x\"]<merged_price[\"adj_close_y\"]].sid\r\n",
    "    \r\n",
    "    stk_ls_holding = list(set(stk_ls_holding) & set(stk_incre))\r\n",
    "    \r\n",
    "    merged_price=pd.merge(today_price,next_date_price,on=\"sid\")\r\n",
    "    merged_price[\"change_rate\"]=merged_price[\"adj_close_y\"]/merged_price[\"adj_close_x\"]-1\r\n",
    "    \r\n",
    "    merged_price = merged_price.set_index(\"sid\").loc[stk_ls_holding].reset_index()\r\n",
    "    \r\n",
    "    \r\n",
    "    return  np.nanmean(merged_price[\"change_rate\"]),len(stk_ls_holding)\r\n",
    "\r\n",
    "for date in trade_dates[:-1]:\r\n",
    "    print(date)\r\n",
    "    stk_to_buy= df_stk_pool_buy[df_stk_pool_buy[\"date\"] == date].sid.values\r\n",
    "    stk_to_sell= df_stk_pool_sell[df_stk_pool_sell[\"date\"] == date].sid.values\r\n",
    "    \r\n",
    "    stk_ls_holding = list(set(stk_ls_holding) - set(stk_to_sell))\r\n",
    "    stk_ls_holding = list(set(stk_ls_holding) | set(stk_to_buy))\r\n",
    "    \r\n",
    "    port_ret_daily.loc[get_next_trade_date(date)], \\\r\n",
    "    port_stk_num.loc[get_next_trade_date(date)] = \\\r\n",
    "    get_daily_ret(stk_ls_holding,date,trade_dates)\r\n",
    "   \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np.cumprod(port_ret_daily+1),label = \"cross_grid\" )\r\n",
    "plt.xticks(rotation=90)\r\n",
    "\r\n",
    "sql=\"select S_INFO_WINDCODE,TRADE_DT,S_DQ_CLOSE FROM AINDEXEODPRICES WHERE S_INFO_WINDCODE ='000300.SH'\"\r\n",
    "index_hq=pd.read_sql(sql,conn)\r\n",
    "index_hq.sort_values(\"TRADE_DT\",inplace=True)\r\n",
    "index_hq = index_hq.set_index(\"TRADE_DT\").loc[\"20170222\":\"20191230\"].reset_index()\r\n",
    "plt.plot(pd.to_datetime(index_hq[\"TRADE_DT\"]),index_hq[\"S_DQ_CLOSE\"]/index_hq[\"S_DQ_CLOSE\"][index_hq.index[0]],label=\"hs300\")\r\n",
    "\r\n",
    "sql=\"select S_INFO_WINDCODE,TRADE_DT,S_DQ_CLOSE FROM AINDEXEODPRICES WHERE S_INFO_WINDCODE ='000905.SH'\"\r\n",
    "index_hq=pd.read_sql(sql,conn)\r\n",
    "index_hq.sort_values(\"TRADE_DT\",inplace=True)\r\n",
    "index_hq = index_hq.set_index(\"TRADE_DT\").loc[\"20170222\":\"20191230\"].reset_index()\r\n",
    "plt.plot(pd.to_datetime(index_hq[\"TRADE_DT\"]),index_hq[\"S_DQ_CLOSE\"]/index_hq[\"S_DQ_CLOSE\"][index_hq.index[0]],label=\"cs500\")\r\n",
    "\r\n",
    "plt.legend()\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_max_drawdown(arr):\r\n",
    "    max_drawdown=0\r\n",
    "    for i in range(len(arr)):\r\n",
    "        cum_ret=np.cumprod(1+arr[i:])\r\n",
    "        if (1 - np.min(cum_ret)) > max_drawdown:\r\n",
    "            max_drawdown = 1 - np.min(cum_ret)\r\n",
    "    return max_drawdown\r\n",
    "\r\n",
    "def get_indicator_df(sid,df):    \r\n",
    "    indicator_df=pd.DataFrame(index=pd.MultiIndex.from_product([sid,[\"stock\",\"strategy\",\"strategy_adj\"]]),\\\r\n",
    "                          columns=[\"tot_return\",\"yearly_ret\",\"daily_volat\",\"yearly_volat\",\"sharpe\",\"yearly_sharpe\",\"max_drawdown\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"tot_return\"] = df[\"stock_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"tot_return\"] = df[\"strategy_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] = np.power(df[\"stock_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] = np.power(df[\"strategy_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"daily_volat\"] = np.nanstd(df[\"change_rate\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"daily_volat\"] = np.nanstd(df[\"trading_profit_loss\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"] = np.nanstd(df[\"change_rate\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"] = np.nanstd(df[\"trading_profit_loss\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"sharpe\"] = np.nanmean(df[\"stock_ret\"]) / np.nanstd(df[\"stock_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"sharpe\"] = np.nanmean(df[\"strategy_ret\"]) / np.nanstd(df[\"strategy_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"max_drawdown\"] = get_max_drawdown(df[\"change_rate\"].dropna().values)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"max_drawdown\"] =  get_max_drawdown(df[\"trading_profit_loss\"].dropna().values) \r\n",
    "    return indicator_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np.cumprod(port_ret_daily+1),label = \"cross_grid\" )\r\n",
    "plt.xticks(rotation=90)\r\n",
    "\r\n",
    "sql=\"select S_INFO_WINDCODE,TRADE_DT,S_DQ_CLOSE FROM AINDEXEODPRICES WHERE S_INFO_WINDCODE ='000300.SH'\"\r\n",
    "index_hq=pd.read_sql(sql,conn)\r\n",
    "index_hq.sort_values(\"TRADE_DT\",inplace=True)\r\n",
    "index_hq = index_hq.set_index(\"TRADE_DT\").loc[\"20170222\":\"20191230\"].reset_index()\r\n",
    "plt.plot(pd.to_datetime(index_hq[\"TRADE_DT\"]),index_hq[\"S_DQ_CLOSE\"]/index_hq[\"S_DQ_CLOSE\"][index_hq.index[0]],label=\"hs300\")\r\n",
    "\r\n",
    "plt.legend()\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "index_hq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_indicator_df([\"portfolio\"],overall_ret)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}