{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we will build synthetic data suitable to Alphalens analysis. This is useful to understand how Alphalens expects the input to be formatted and also it is a good testing environment to experiment with Alphalens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    \n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import (DataFrame, date_range)\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "from data_tools.api import *\n",
    "from utilscht.Data import *\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from alphalens.performance import *\n",
    "from alphalens.tears import ( create_returns_tear_sheet,\n",
    "                      create_information_tear_sheet,\n",
    "                      create_turnover_tear_sheet,\n",
    "                      create_summary_tear_sheet,\n",
    "                      create_full_tear_sheet,\n",
    "                      create_event_returns_tear_sheet,\n",
    "                      create_event_study_tear_sheet)\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "DB_INFO = dict(host='192.168.1.234',\n",
    "               user='winduser',\n",
    "               password='1qaz@WSX',\n",
    "               db='wind')\n",
    "\n",
    "conn = pymysql.connect(**DB_INFO, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取价格数据和一致预期数据\n",
    "'''\n",
    "sql = \"\"\"SELECT S_INFO_WINDCODE, TRADE_DT, S_DQ_ADJOPEN from ASHAREEODPRICES where TRADE_DT between '20170101' and '20191031'\"\"\"   \n",
    "df_open = pd.read_sql_query(sql, conn)\n",
    "df_open=df_open.rename(columns={\"S_INFO_WINDCODE\":\"sid\",\"TRADE_DT\":\"DataDate\"})\n",
    "df_open=df_open.sort_values([\"sid\",\"DataDate\"])\n",
    "df_open.to_csv(\"open_price.csv\",index=False)\n",
    "'''\n",
    "df_open=pd.read_csv(\"open_price.csv\",dtype={\"DataDate\":str})\n",
    "df_con_est_eps=pd.read_csv(r\"/home/ywang/proj_3/data/con_eps_my.csv\",dtype={\"DataDate\":str})\n",
    "df_close=pd.read_csv(r\"/home/ywang/proj_3/data/close_price.csv\",dtype={\"DataDate\":str})\n",
    "\n",
    "df_con_est_eps=df_con_est_eps.set_index([\"DataDate\",\"sid\",\"REPORTING_PERIOD\"]).unstack(level=2)[\"con_est_eps\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywang/env/dev/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in sqrt\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#构造一致预期相关的因子\n",
    "def con_ep_calcu(df):\n",
    "    year=df[\"year\"][df.index[0]]\n",
    "    df[\"con_ep\"]=df[int(year+\"1231\")]/df[\"S_DQ_CLOSE\"]\n",
    "    \n",
    "    month_to_nextyear=df[\"DataDate\"].apply(lambda x:12-int(x[4:6]))\n",
    "    rolling_eps=df[int(year+\"1231\")]*month_to_nextyear/12+df[int(str(int(year)+1)+\"1231\")]*(12-month_to_nextyear)/12\n",
    "    df[\"con_ep_rolling\"]=rolling_eps/df[\"S_DQ_CLOSE\"]\n",
    "    \n",
    "    eps_0=df[int(str(int(year)-1)+\"1231\")]\n",
    "    eps_1=df[int(year+\"1231\")]\n",
    "    eps_2=df[int(str(int(year)+1)+\"1231\")]\n",
    "    growth=np.sqrt(eps_2/eps_0)-1\n",
    "    df[\"growth\"]=growth\n",
    "    \n",
    "    df[\"con_PEG\"]=1/(df[\"con_ep_rolling\"]*df[\"growth\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "#df_con_est_eps=pd.merge(df_con_est_eps,df_close,on=[\"sid\",\"DataDate\"],how=\"left\")\n",
    "df_con_est_eps[\"year\"]=df_con_est_eps[\"DataDate\"].apply(lambda x:x[0:4])\n",
    "df_con_est_eps=df_con_est_eps.groupby(\"year\").apply(con_ep_calcu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行市值行业中性化的函数\n",
    "def Neutralize(df):\n",
    "    factor=np.array(df[factor_name])\n",
    "    indus_dummy=np.array(pd.get_dummies(df[\"L1_INDUSTRY\"]))\n",
    "    size=np.array(df[\"mktcap\"])\n",
    "    \n",
    "    ols_result=sm.OLS(factor,np.column_stack([size,indus_dummy])).fit()\n",
    "    factor=ols_result.resid\n",
    "    \n",
    "    mu  =  np.mean(factor)\n",
    "    sigma = np.std(factor)\n",
    "    factor[factor > mu + 3 * sigma] = mu + 3 * sigma\n",
    "    factor[factor < mu - 3 * sigma] = mu - 3 * sigma\n",
    "    factor=(factor-np.mean(factor))/np.std(factor)\n",
    "    df[factor_name+\"_n\"]=factor\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def Factor_Test(factor_name,df_con_est_eps,df_open):\n",
    "    #获取因子数据\n",
    "    factor_data=pd.pivot_table(df_con_est_eps,factor_name,index=\"DataDate\",columns=\"sid\")\n",
    "    factor_data=factor_data.replace(0,np.nan).replace(np.inf,np.nan).replace(-np.inf,np.nan).fillna(method=\"ffill\")\n",
    "    factor_data=factor_data.dropna(axis=1)\n",
    "    factor_data=factor_data.shift(1).dropna()\n",
    "    \n",
    "    #获取价格数据\n",
    "    price_data=pd.pivot_table(df_open,\"S_DQ_ADJOPEN\",index=\"DataDate\",columns=\"sid\")\n",
    "    \n",
    "    #进行适当变换\n",
    "    factor_data.index.name='date'\n",
    "    price_data.index.name='date'\n",
    "    factor_data.index=pd.to_datetime(factor_data.index)\n",
    "    price_data.index=pd.to_datetime(price_data.index)\n",
    "    factor_data=factor_data.stack()\n",
    "    \n",
    "    #加入市值和行业信息\n",
    "    indus_size_df=query_table(\"DailyBar\",start_date=\"20160101\",end_date=\"20191031\",fields=[\"L1_INDUSTRY\",\"mktcap\"])\n",
    "    indus_size_df[\"date\"]=pd.to_datetime(indus_size_df[\"DataDate\"].apply(str))\n",
    "    factor_data=pd.merge(factor_data.to_frame(factor_name).reset_index(),indus_size_df,on=[\"sid\",\"date\"])\n",
    "    \n",
    "    #进行市值行业中性化\n",
    "    factor_data=factor_data.groupby(\"date\").apply(Neutralize)\n",
    "    factor_data=factor_data[[\"date\",\"sid\",factor_name+\"_n\"]].set_index([\"date\",\"sid\"])\n",
    "    \n",
    "    #调用Alphalens 中的函数进行因子分析（分层测试和 IC 测试）\n",
    "    factor_price_data = get_clean_factor_and_forward_returns(\n",
    "        factor_data,\n",
    "        price_data,\n",
    "        quantiles=10,\n",
    "        periods=(3,5,10,20,30))\n",
    "\n",
    "    create_summary_tear_sheet(factor_price_data, long_short=False, group_neutral=False, by_group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
