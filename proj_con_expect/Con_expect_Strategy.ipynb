{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from data_tools.api import *\r\n",
    "from utilscht.Data import *\r\n",
    "import pymysql\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.backends.backend_pdf import PdfPages\r\n",
    "import statsmodels.api as sm\r\n",
    "from joblib import Parallel,delayed\r\n",
    "import datetime\r\n",
    "from scipy.interpolate import interp1d\r\n",
    "import logging\r\n",
    "%config InlineBackend.figure_format ='retina'\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "\r\n",
    "\r\n",
    "START_YEAR=2015\r\n",
    "plt.rcParams['figure.figsize']=(8,6)\r\n",
    "plt.rcParams['font.size']=10\r\n",
    "pd.set_option(\"precision\",4)\r\n",
    "\r\n",
    "DB_INFO = dict(host='192.168.1.234',\r\n",
    "               user='winduser',\r\n",
    "               password='1qaz@WSX',\r\n",
    "               db='wind')\r\n",
    "\r\n",
    "conn = pymysql.connect(**DB_INFO, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logging.basicConfig(level=logging.DEBUG,#控制台打印的日志级别\r\n",
    "                    filename=r'logging/Con_expect_Strategy.log',\r\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\r\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\r\n",
    "                    format='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'#日志格式\r\n",
    "                   )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def apply_parallel(df_grouped, func, n_jobs=16, backend='loky', as_index=True, **kwargs):\r\n",
    "    \"\"\"\r\n",
    "    This is for parallel between grouped generated by pd.DataFrame.groupby\r\n",
    "    :param df_grouped:\r\n",
    "    :param func:\r\n",
    "    :param n_jobs:\r\n",
    "    :param backend:\r\n",
    "    :param kwargs:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    names = []\r\n",
    "    groups = []\r\n",
    "    for name, group in df_grouped:\r\n",
    "        names.append(name)\r\n",
    "        groups.append(group)\r\n",
    "\r\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=5, backend=backend, batch_size='auto') \\\r\n",
    "        (delayed(func)(group, **kwargs) for group in groups)\r\n",
    "\r\n",
    "    return pd.concat(results, keys=names if as_index else None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选取沪深300 基本面较好的股票"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"df_top_comp = pd.read_csv(r\"../tempory task/result/Top_stocks_each_indus.csv\",index_col=\"Unnamed: 0\")\r\n",
    "df_top_comp = df_top_comp[(0.05<=df_top_comp[\"BarraSGRO\"]) & (0.05<=df_top_comp[\"BarraEGRO\"]) &(df_top_comp[\"BarraSGRO\"]<=0.5) &(df_top_comp[\"BarraEGRO\"]<=0.5)]\r\n",
    "stk_ls= df_top_comp.sid\r\n",
    "\r\n",
    "df_hs300=query_table(\"DailyBar\",start_date='20190506',end_date='20190506',fields=[\"w_hs300\"])\r\n",
    "stk_hs300 = df_hs300[df_hs300[\"w_hs300\"]!=0].sid\r\n",
    "\r\n",
    "stk_ls=list(set(stk_ls) & set(stk_hs300))\"\"\"\r\n",
    "\r\n",
    "stk_ls = \\\r\n",
    "[\"000001.SZ\",\"000002.SZ\",\r\n",
    "\"000333.SZ\",\"000538.SZ\",\r\n",
    "\"000568.SZ\",\"000651.SZ\",\r\n",
    "\"000661.SZ\",\"000858.SZ\",\r\n",
    "\"002032.SZ\",\"002050.SZ\",\r\n",
    "\"002142.SZ\",\"002179.SZ\",\r\n",
    "\"002311.SZ\",\"002415.SZ\",\r\n",
    "\"002475.SZ\",\"300003.SZ\",\r\n",
    "\"300015.SZ\",\"300124.SZ\",\r\n",
    "\"600009.SH\",\"600036.SH\",\r\n",
    "\"600048.SH\",\"600104.SH\",\r\n",
    "\"600176.SH\",\"600196.SH\",\r\n",
    "\"600276.SH\",\"600309.SH\",\r\n",
    "\"600332.SH\",\"600340.SH\",\r\n",
    "\"600406.SH\",\"600436.SH\",\r\n",
    "\"600438.SH\",\"600487.SH\",\r\n",
    "\"600498.SH\",\"600519.SH\",\r\n",
    "\"600522.SH\",\"600585.SH\",\r\n",
    "\"600588.SH\",\"600660.SH\",\r\n",
    "\"600690.SH\",\"600741.SH\",\r\n",
    "\"600809.SH\",\"600887.SH\",\r\n",
    "\"601166.SH\",\"601155.SH\",\r\n",
    "\"601318.SH\",\"601607.SH\",\r\n",
    "\"601668.SH\",\"601877.SH\",\r\n",
    "\"601888.SH\",\"601933.SH\",\r\n",
    "\"603160.SH\",\"603288.SH\",\r\n",
    "]\r\n",
    "\r\n",
    "#获取一致预期数据\r\n",
    "con_expect_data=pd.read_csv(r\"result/con_eps_my_v3.csv\",dtype={\"DataDate\":str,\"REPORTING_PERIOD\":str})\r\n",
    "con_expect_data=con_expect_data.groupby([\"sid\",\"REPORTING_PERIOD\"],as_index=False)\\\r\n",
    "                    .apply(lambda x:x.replace(0,np.nan).fillna(method=\"ffill\"))\r\n",
    "open_price_adj=pd.read_csv(r\"data/open_price.csv\",dtype={\"DataDate\":str})\r\n",
    "con_expect_data=con_expect_data[[\"sid\",\"REPORTING_PERIOD\",\"DataDate\",\"con_est_eps\"]]\r\n",
    "\r\n",
    "stock_pool_est_eps=con_expect_data.set_index(\"sid\")#.loc[stk_ls]\r\n",
    "stock_pool_est_eps=stock_pool_est_eps[stock_pool_est_eps[\"DataDate\"]>\"{}1101\".format(START_YEAR)].reset_index()\r\n",
    "\r\n",
    "#加入收盘价序列\r\n",
    "df_close=pd.read_csv(r\"data/close_price.csv\",dtype={\"DataDate\":str})\r\n",
    "\r\n",
    "stock_pool_est_eps=pd.merge(stock_pool_est_eps,df_close,on=[\"sid\",\"DataDate\"],how=\"left\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 如何确定合理pe\n",
    "1. 个股过去两年pe—ttm中位数 0.5\n",
    "2. 行业当前pe水平 0.3\n",
    "3. 行业pe过去两年中位数 0.2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_df = df_PETTM_2y_rollingmedian[df_PETTM_2y_rollingmedian[\"sid\"]==\"000655.SZ\"]\r\n",
    "plt.plot(pd.to_datetime(temp_df[\"DataDate\"]),\r\n",
    "    temp_df[\"pe_2y_rollingmedian\"].values)\r\n",
    "plt.plot(pd.to_datetime(temp_df[\"DataDate\"]),\r\n",
    "    temp_df[\"S_VAL_PE_TTM\"].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PETTM.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groups = df_PETTM.groupby([\"L1_INDUSTRY\",\"DataDate\"])\r\n",
    "get_indus_pe_median = lambda x: pd.DataFrame(data=[[np.nanmedian(x[\"S_VAL_PE_TTM\"]),x[\"L1_INDUSTRY\"].iloc[0],x[\"DataDate\"].iloc[0]]],\\\r\n",
    "                                             columns=[\"indus_pe_meidna\",\"industry\",\"DataDate\"])\r\n",
    "get_indus_pe_mean = lambda x: pd.DataFrame(data=[[np.nanmean(x[\"S_VAL_PE_TTM\"]),x[\"L1_INDUSTRY\"].iloc[0],x[\"DataDate\"].iloc[0]]],\\\r\n",
    "                                             columns=[\"indus_pe_mean\",\"industry\",\"DataDate\"])\r\n",
    "df_indus_pe_median = apply_parallel(groups, get_indus_pe_median,as_index=True).reset_index(drop=True)\r\n",
    "df_indus_pe_mean = apply_parallel(groups, get_indus_pe_mean,as_index=True).reset_index(drop=True)\r\n",
    "df_indus_pe_median\r\n",
    "df_indus_pe_mean"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def indus_pe_analysis(df):\r\n",
    "    df_indus = df.set_index(\"DataDate\")\r\n",
    "    df_indus.index = pd.to_datetime(df_indus.index)\r\n",
    "    \r\n",
    "    df_indus[\"indus_pe_mean\"].plot()\r\n",
    "    plt.grid()\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "df_indus_pe_mean.groupby([\"industry\"]).apply(indus_pe_analysis)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#利用过去两年 PE中位数作为当前合理的 PE\r\n",
    "df_PETTM=pd.read_csv(r\"data/PETTM.csv\",dtype={\"DataDate\":str})\r\n",
    "df_indus=query_table(\"DailyBar\",start_date='20120101',end_date='20200310',fields=[\"L1_INDUSTRY\"])\r\n",
    "df_indus[\"DataDate\"] = df_indus[\"DataDate\"].apply(str)\r\n",
    "df_PETTM = df_PETTM.merge(df_indus,on=[\"sid\",\"DataDate\"])\r\n",
    "\r\n",
    "def adj_by_indus_pe(df):\r\n",
    "    indus_pe = np.nanmedian(df[\"S_VAL_PE_TTM\"]) \r\n",
    "    df[\"S_VAL_PE_TTM\"] = np.clip(df[\"S_VAL_PE_TTM\"].values, 0,indus_pe*2)\r\n",
    "    return df\r\n",
    "groups = df_PETTM.groupby([\"L1_INDUSTRY\",\"DataDate\"])\r\n",
    "df_PETTM = apply_parallel(groups, adj_by_indus_pe).reset_index(drop=True)\r\n",
    "df_PETTM = df_PETTM.sort_values([\"sid\",\"DataDate\"])\r\n",
    "\r\n",
    "def Rolling_Median(df):\r\n",
    "    df[\"S_VAL_PE_TTM\"]=df[\"S_VAL_PE_TTM\"].fillna(method='bfill')\r\n",
    "    df[\"pe_2y_rollingmedian\"]=df[\"S_VAL_PE_TTM\"].rolling(252*1).apply(lambda x:np.percentile(x,10))\r\n",
    "    #df[\"pe_2y_rollingmedian\"]=np.minimum(df[\"pe_2y_rollingmedian\"].values,\\\r\n",
    "    #                                      df[\"S_VAL_PE_TTM\"].values*1.5)\r\n",
    "    return df\r\n",
    "\r\n",
    "grouped=df_PETTM.groupby(\"sid\")\r\n",
    "df_PETTM_2y_rollingmedian=apply_parallel(grouped,Rolling_Median)\r\n",
    "stock_pool_est_eps=pd.merge(stock_pool_est_eps,df_PETTM_2y_rollingmedian,on=[\"sid\",\"DataDate\"],how=\"left\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stock_pool_est_eps.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试策略在单只股票下的具体表现"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def Get_prices(daily_df):\r\n",
    "    close=daily_df[\"S_DQ_ADJCLOSE\"].values[0]\r\n",
    "    date=daily_df[\"DataDate\"].values[0]\r\n",
    "    \r\n",
    "    pe = np.nan\r\n",
    "    prices=np.array([0,0,0,0],dtype=float)\r\n",
    "    for i in range(4):\r\n",
    "        try:\r\n",
    "            reporting_period=str(int(date[0:4])+i-1)+\"1231\"\r\n",
    "            con_est_eps=daily_df[daily_df[\"REPORTING_PERIOD\"]==reporting_period][\"con_est_eps\"].values[0]\r\n",
    "            pe=daily_df[daily_df[\"REPORTING_PERIOD\"]==reporting_period][\"pe_2y_rollingmedian\"].values[0]\r\n",
    "            prices[i]=con_est_eps*pe\r\n",
    "        except IndexError as e:\r\n",
    "            pass\r\n",
    "        \r\n",
    "    #填充第三年数据\r\n",
    "    if prices[2]==0:\r\n",
    "        prices[2]= prices[1]+(prices[1]-prices[0])\r\n",
    "    \r\n",
    "    #处理四年con_eps 非线性增长的情况\r\n",
    "    if prices[0]>prices[1] and prices[1]<prices[2]:\r\n",
    "        prices[0] = prices[1]-(prices[2]-prices[1])\r\n",
    "    elif prices[1]>prices[2] and prices[0]<prices[2]:\r\n",
    "        prices[1] = (prices[0]+prices[2])/2\r\n",
    "    \r\n",
    "    #填充第四年数据\r\n",
    "    if prices[3] ==0:\r\n",
    "        prices[3]=prices[2]+(prices[2]-prices[1])\r\n",
    "    \r\n",
    "        \r\n",
    "    #进行平滑（向未来一年进行滚动）\r\n",
    "    month , day =( int(date[4:6]), int(date[6:8]) )\r\n",
    "    day_num = (month-1)*30 +day\r\n",
    "    prices_smooth = np.array([0,0,0],dtype=float)\r\n",
    "    for i in range(3):\r\n",
    "        prices_smooth[i] = (prices[i]*(360-day_num)+prices[i+1]*day_num)/360\r\n",
    "    \r\n",
    "    prices_smooth.sort()\r\n",
    "    return pd.DataFrame(data=[[prices_smooth[0],prices_smooth[1],prices_smooth[2],close,pe]],columns=[\"p0\",\"p1\",\"p2\",\"close\",\"pe_rollingmedian\"])\r\n",
    "\r\n",
    "def get_level(close,prices):        \r\n",
    "    level=0\r\n",
    "    benchmark=0\r\n",
    "    for p in prices:\r\n",
    "        if close<p:\r\n",
    "            return level+(close-benchmark)/(p-benchmark)\r\n",
    "        else:\r\n",
    "            level = level+1\r\n",
    "            benchmark = p\r\n",
    "    if (prices[2]-prices[1])/prices[1]>0.1:\r\n",
    "        return level+(close-benchmark)/(prices[2]-prices[1])\r\n",
    "    else:\r\n",
    "        return level+(close-benchmark)/(prices[1]*0.1)\r\n",
    "\r\n",
    "def get_level_from_rolling_data(arr):\r\n",
    "    current_close=arr[251,3]\r\n",
    "    current_estprices=arr[251,0:3]\r\n",
    "    \r\n",
    "    close_series=arr[:,3]\r\n",
    "    bottom_series=arr[:,0]\r\n",
    "    middle_series = arr[:,1]\r\n",
    "    ##params adjusting\r\n",
    "    if np.sum(close_series<(bottom_series+middle_series)/2)/len(close_series)>0.80:\r\n",
    "        current_estprices_adj = current_close/current_estprices[1]*current_estprices\r\n",
    "    else:\r\n",
    "        current_estprices_adj = current_estprices\r\n",
    "    return get_level(current_close,current_estprices),get_level(current_close,current_estprices_adj)\r\n",
    "\r\n",
    "def get_position(over_level):\r\n",
    "    grid=np.linspace(1.0,3.7,5)\r\n",
    "    position=np.linspace(1,0,6)\r\n",
    "\r\n",
    "    count=0\r\n",
    "    for i in grid:\r\n",
    "        if over_level>i:\r\n",
    "            count=count+1\r\n",
    "        else:\r\n",
    "            break\r\n",
    "    return position[count]\r\n",
    "\r\n",
    "def get_max_drawdown(arr):\r\n",
    "    max_drawdown=0\r\n",
    "    for i in range(len(arr)):\r\n",
    "        cum_ret=np.cumprod(1+arr[i:])\r\n",
    "        if (1 - np.min(cum_ret)) > max_drawdown:\r\n",
    "            max_drawdown = 1 - np.min(cum_ret)\r\n",
    "    return max_drawdown\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#analyse the perfromance of the strategy on single stock\r\n",
    "def Single_Stock_Analysis(df):\r\n",
    "    \"\"\"\r\n",
    "    #this function is used to analysis the con_est_price versus the real_trading price \r\n",
    "    #,and use the timing strategy to get the right position(0-1) at each date，and then:\r\n",
    "    #1.plot the close_price and the con_est_prices(p0,p1,p2)\r\n",
    "    #2.calculate the over_level of the stock_price\r\n",
    "    #3.plot the trading result of this stock(cumulative return of trading the stock)\r\n",
    "    #4.calculate the indicator for the strategy ret\r\n",
    "    \"\"\"    \r\n",
    "    sid=df[\"sid\"][df.index[0]]\r\n",
    "    \r\n",
    "    #1.plot the close_price and the con_est_prices(p0,p1,p2)     \r\n",
    "    df=df.groupby(\"DataDate\").apply(Get_prices)\r\n",
    "    df=df.reset_index().set_index(\"DataDate\")\r\n",
    "    del df[\"level_1\"]\r\n",
    "    df.index=pd.to_datetime(df.index)\r\n",
    "    \r\n",
    "    plt.xticks(rotation=90)\r\n",
    "    plt.plot(df[[\"p0\",\"p1\",\"p2\",\"close\"]])\r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.title(sid+\" close_price and the con_est_prices\")\r\n",
    "    try:\r\n",
    "        test_con_timing.savefig()\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "    #2.plot the over_level of the stock_price   \r\n",
    "    df[\"over_level\"]=np.nan\r\n",
    "    df[\"over_level_adj\"] =np.nan \r\n",
    "    for i in range(251,len(df)):\r\n",
    "        rolling_arr = df.iloc[np.arange(i-251,i+1)]\r\n",
    "        df.iloc[i,5:7] = get_level_from_rolling_data(np.array(rolling_arr))\r\n",
    "        \r\n",
    "    df.to_csv(r\"result/stk_est_eps/est_eps_{}.csv\".format(sid),index_label=\"DataDate\")\r\n",
    "    #3.plot the trading result of this stock(cumulative return of trading the stock)\r\n",
    "    df[\"position\"]=df[\"over_level\"].apply(get_position)\r\n",
    "    df[\"position_adj\"]=df[\"over_level_adj\"].apply(get_position)\r\n",
    "    open_price_adj[\"DataDate\"]=pd.to_datetime(open_price_adj[\"DataDate\"])\r\n",
    "    df[\"change_rate\"]=open_price_adj.set_index(\"sid\").loc[sid].set_index(\"DataDate\").pct_change().shift(-2)\r\n",
    "    df[\"trading_profit_loss\"]=df[\"position\"]*df[\"change_rate\"]\r\n",
    "    df[\"trading_profit_loss_adj\"]=df[\"position_adj\"]*df[\"change_rate\"]\r\n",
    "    df[\"strategy_ret\"]=np.cumprod(1+df[\"trading_profit_loss\"].fillna(0))\r\n",
    "    df[\"strategy_ret_adj\"]=np.cumprod(1+df[\"trading_profit_loss_adj\"].fillna(0))\r\n",
    "    df[\"stock_ret\"]=np.cumprod(1+df[\"change_rate\"].fillna(0))\r\n",
    "    \r\n",
    "\r\n",
    "    plt.xticks(rotation=90)\r\n",
    "    plt.plot(df[\"strategy_ret_adj\"],label=\"strategy_ret_adj\",color='tab:blue')\r\n",
    "    plt.plot(df[\"strategy_ret\"],label=\"strategy_ret\",color='tab:green')\r\n",
    "    plt.plot(df[\"stock_ret\"],label=\"stock_ret\",color='tab:red')\r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.title(sid+\" cumulative return of trading the stock\")\r\n",
    "    test_con_timing.savefig()\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "    #4.calculate the indicator for the strategy ret\r\n",
    "            \r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"tot_return\"] = df[\"stock_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"tot_return\"] = df[\"strategy_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"tot_return\"] = df[\"strategy_ret_adj\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] = np.power(df[\"stock_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] = np.power(df[\"strategy_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_ret\"] = np.power(df[\"strategy_ret_adj\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"daily_volat\"] = np.nanstd(df[\"change_rate\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"daily_volat\"] = np.nanstd(df[\"trading_profit_loss\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"daily_volat\"] = np.nanstd(df[\"trading_profit_loss_adj\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"] = np.nanstd(df[\"change_rate\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"] = np.nanstd(df[\"trading_profit_loss\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_volat\"] = np.nanstd(df[\"trading_profit_loss_adj\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"sharpe\"] = np.nanmean(df[\"stock_ret\"]) / np.nanstd(df[\"stock_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"sharpe\"] = np.nanmean(df[\"strategy_ret\"]) / np.nanstd(df[\"strategy_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"sharpe\"] = np.nanmean(df[\"strategy_ret_adj\"]) / np.nanstd(df[\"strategy_ret_adj\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"max_drawdown\"] = get_max_drawdown(df[\"change_rate\"].dropna().values)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"max_drawdown\"] =  get_max_drawdown(df[\"trading_profit_loss\"].dropna().values)\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"max_drawdown\"] =  get_max_drawdown(df[\"trading_profit_loss_adj\"].dropna().values)\r\n",
    "    \r\n",
    "    indicator_df_singlestock =pd.DataFrame(indicator_df.loc[sid],dtype=float).reset_index()\r\n",
    "    fig = plt.figure(figsize=(8,3))\r\n",
    "    ax = plt.subplot(111)\r\n",
    "    ax.axis('off')\r\n",
    "    ax.table(cellText=indicator_df_singlestock.round(4).values, colLabels=indicator_df_singlestock.columns, bbox=[0,0,1,1])\r\n",
    "    plt.title(\"the judging indicator of strategy ({})\".format(sid))\r\n",
    "    test_con_timing.savefig(fig)\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "    return df[['stock_ret','strategy_ret','strategy_ret_adj']]\r\n",
    "    \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_df = stock_pool_est_eps.groupby(\"sid\").get_group(\"000001.SZ\")\r\n",
    "Single_Stock_Analysis(test_df)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#过去两年 PE 中位数作为滚动 PE 值，回测时间 2015-01-01 到 2020-03-10\r\n",
    "test_con_timing=PdfPages('result//test_overlevel_timing_stock_baima_pe10_smooth_v5.pdf')\r\n",
    "indicator_df=pd.DataFrame(index=pd.MultiIndex.from_product([stk_ls,[\"stock\",\"strategy\",\"strategy_adj\"]]),\\\r\n",
    "                          columns=[\"tot_return\",\"yearly_ret\",\"daily_volat\",\"yearly_volat\",\"sharpe\",\"yearly_sharpe\",\"max_drawdown\"])\r\n",
    "result_df=stock_pool_est_eps.groupby(\"sid\").apply(Single_Stock_Analysis)\r\n",
    "test_con_timing.close()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def file_store(df):\r\n",
    "    sid=df[\"sid\"].iloc[0]\r\n",
    "    \r\n",
    "    result_df=df.groupby(\"DataDate\").apply(Get_prices)\r\n",
    "    result_df=result_df.reset_index().set_index(\"DataDate\")\r\n",
    "    del result_df[\"level_1\"]\r\n",
    "    result_df.index=pd.to_datetime(result_df.index)\r\n",
    "\r\n",
    "    result_df[\"over_level\"] = result_df[[\"p0\",\"p1\",\"p2\",\"close\"]].\\\r\n",
    "                                apply(lambda x:get_level(x[3],x[0:3]),axis = 1)\r\n",
    "    \r\n",
    "    result_df.to_csv(r\"result/stk_est_eps/est_eps_{}.csv\".format(sid),index_label=\"DataDate\")\r\n",
    "\r\n",
    "groups = stock_pool_est_eps.groupby(\"sid\")\r\n",
    "apply_parallel(groups,file_store)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_max_drawdown(arr):\r\n",
    "    max_drawdown=0\r\n",
    "    for i in range(60,len(arr)):\r\n",
    "        cum_ret=np.cumprod(1+arr[i:])\r\n",
    "        if (1 - np.min(cum_ret)) > max_drawdown:\r\n",
    "            max_drawdown = 1 - np.min(cum_ret)\r\n",
    "    return max_drawdown\r\n",
    "\r\n",
    "def get_indicator_df(sid,df):    \r\n",
    "    indicator_df=pd.DataFrame(index=pd.MultiIndex.from_product([sid,[\"stock\",\"strategy\",\"strategy_adj\"]]),\\\r\n",
    "                          columns=[\"tot_return\",\"yearly_ret\",\"daily_volat\",\"yearly_volat\",\"sharpe\",\"yearly_sharpe\",\"max_drawdown\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"tot_return\"] = df[\"stock_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"tot_return\"] = df[\"strategy_ret\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"tot_return\"] = df[\"strategy_ret_adj\"].iloc[-1]-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] = np.power(df[\"stock_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] = np.power(df[\"strategy_ret\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_ret\"] = np.power(df[\"strategy_ret_adj\"].iloc[-1],252/len(df))-1\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"daily_volat\"] = np.nanstd(df[\"change_rate\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"daily_volat\"] = np.nanstd(df[\"trading_profit_loss\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"daily_volat\"] = np.nanstd(df[\"trading_profit_loss_adj\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"] = np.nanstd(df[\"change_rate\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"] = np.nanstd(df[\"trading_profit_loss\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_volat\"] = np.nanstd(df[\"trading_profit_loss_adj\"])*np.sqrt(252)\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"sharpe\"] = np.nanmean(df[\"stock_ret\"]) / np.nanstd(df[\"stock_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"sharpe\"] = np.nanmean(df[\"strategy_ret\"]) / np.nanstd(df[\"strategy_ret\"])\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"sharpe\"] = np.nanmean(df[\"strategy_ret_adj\"]) / np.nanstd(df[\"strategy_ret_adj\"])\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"stock\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"stock\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"strategy\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"strategy\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_sharpe\"] = indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_ret\"] / indicator_df.loc[(sid,\"strategy_adj\"),\"yearly_volat\"]\r\n",
    "    indicator_df.loc[(sid,\"stock\"),\"max_drawdown\"] = get_max_drawdown(df[\"change_rate\"].dropna().values)\r\n",
    "    indicator_df.loc[(sid,\"strategy\"),\"max_drawdown\"] =  get_max_drawdown(df[\"trading_profit_loss\"].dropna().values)\r\n",
    "    indicator_df.loc[(sid,\"strategy_adj\"),\"max_drawdown\"] =  get_max_drawdown(df[\"trading_profit_loss_adj\"].dropna().values)\r\n",
    "    \r\n",
    "    return indicator_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_con_timing=PdfPages(\"result//test_overlevel_timing_port_baima_pe30_smooth.pdf\")\n",
    "\n",
    "overall_ret=result_df.unstack(level=1).mean(axis=0).to_frame(\"ret\").unstack(level=0)[\"ret\"]\n",
    "\n",
    "overall_ret.plot()\n",
    "plt.title(\"stock portfolio test result\")\n",
    "test_con_timing.savefig()\n",
    "overall_ret['change_rate']= overall_ret['stock_ret'].pct_change().fillna(0)\n",
    "overall_ret['trading_profit_loss']= overall_ret[\"strategy_ret\"].pct_change().fillna(0)\n",
    "overall_ret['trading_profit_loss_adj']= overall_ret[\"strategy_ret_adj\"].pct_change().fillna(0)\n",
    "\n",
    "indicator_df=get_indicator_df([\"portfolio\"],overall_ret)\n",
    "indicator_df_singlestock =pd.DataFrame(indicator_df.loc[\"portfolio\"],dtype=float).reset_index()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "ax = plt.subplot(111)\n",
    "ax.axis('off')\n",
    "ax.table(cellText=indicator_df_singlestock.round(4).values, colLabels=indicator_df_singlestock.columns, bbox=[0,0,1,1])\n",
    "plt.title(\"the judging indicator of strategy ({})\".format(\"portfolio\"))\n",
    "test_con_timing.savefig(fig)\n",
    "plt.show()\n",
    "\n",
    "test_con_timing.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## con_eps zyyx数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_con_eps_zyyx=pd.read_csv(\"data//con_eps_zyyx.csv\")\n",
    "df_con_eps_zyyx.sort_values([\"stock_code\",\"con_date\"],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_df=df_con_eps_zyyx[df_con_eps_zyyx[\"stock_code\"]==651]\n",
    "temp_df=temp_df[temp_df[\"con_date\"]>='2017-03-01']\n",
    "temp_df=temp_df[temp_df[\"con_year\"]==2018]\n",
    "temp_df.iloc[0:60]\n",
    "plt.plot(pd.to_datetime(temp_df[\"con_date\"].values),temp_df[\"con_eps\"].values)\n",
    "plt.grid()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PE 走势"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_df=df_PETTM_2y_rollingmedian[df_PETTM_2y_rollingmedian[\"sid\"] =='000568.SZ']\n",
    "temp_df.sort_values('DataDate',inplace=True)\n",
    "plt.plot(pd.to_datetime(temp_df[\"DataDate\"].values),temp_df[\"S_VAL_PE_TTM\"].values)\n",
    "plt.plot(pd.to_datetime(temp_df[\"DataDate\"].values),temp_df[\"pe_2y_rollingmedian\"].values)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## con_eps 计算数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_df=stock_pool_est_eps[stock_pool_est_eps[\"sid\"]=='000651.SZ']\n",
    "temp_df=temp_df[temp_df[\"DataDate\"]>='20170301']\n",
    "temp_df=temp_df[temp_df[\"REPORTING_PERIOD\"]=='20181231']\n",
    "temp_df.iloc[0:60]\n",
    "plt.plot(pd.to_datetime(temp_df[\"DataDate\"].values),temp_df[\"con_est_eps\"].values)\n",
    "plt.grid()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Single_Stock_Analysis(stock_pool_est_eps.groupby(\"sid\").get_group(\"002050.SZ\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#通过滤波去除高频分量\n",
    "from scipy import signal\n",
    "\n",
    "def FFT(price_series):\n",
    "    Wn = 0.4\n",
    "    b, a = signal.butter(8, Wn, 'lowpass')   #配置滤波器 8 表示滤波器的阶数\n",
    "    filtedData = signal.filtfilt(b, a, price_series)  #data为要过滤的信号\n",
    "    return filtedData"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data=stock_pool_est_eps.iloc[0:40]['S_DQ_CLOSE']\n",
    "plt.plot(test_data,label='original')\n",
    "plt.plot(FFT(test_data),label='filtered')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}